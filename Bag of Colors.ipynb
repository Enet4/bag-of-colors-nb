{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my personal attempt at making a bag of colors implementation. It was made into an interactive notebook, so that it ends up well documented and easy to pick up by someone else. \n",
    "\n",
    "For more details on this algorithm, please see the original paper:\n",
    "\n",
    "> Christian Wenger, Matthijs Douze, Hervé Jégou, \"Bag-of-colors for improved image search\". Online: <https://dl.acm.org/citation.cfm?id=2072298.2072034>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageCms, ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import faiss\n",
    "import h5py as h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my experiments, I have used the data set from the [ImageCLEF](http://imageclef.org) 2018 caption challenge. Any other sufficiently large image data set will work as well. Nevertheless, checking other implementation details is recommended: the image chunking block size was adjusted to work for smaller images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BLOCKS = 256\n",
    "BLOCK_SIZE = 10 # original is 16\n",
    "\n",
    "# update constants to point to a directory of images\n",
    "DATA_DIR = \"training_data\"\n",
    "TEST_DATA_DIR = \"testing_data\"\n",
    "# we'll pick a small sample of the data set for experimentation purposes \n",
    "N_DATA = 25\n",
    "SAMPLE_FILES = [path.join(DATA_DIR, fname) for (i, fname) in zip(range(N_DATA), os.listdir(DATA_DIR))]\n",
    "# all files!\n",
    "ALL_FILES = [path.join(DATA_DIR, fname) for (i, fname) in enumerate(os.listdir(DATA_DIR))]\n",
    "ALL_FILES.sort()\n",
    "assert len(ALL_FILES) > 10000\n",
    "TEST_FILES = [path.join(TEST_DATA_DIR, fname) for (i, fname) in enumerate(os.listdir(TEST_DATA_DIR))]\n",
    "TEST_FILES.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's pick up one image and show how it should be adapted for the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = Image.open(SAMPLE_FILES[4])\n",
    "sample_image = sample_image.resize([160, 160])\n",
    "_ = plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the article says about BoCs:\n",
    "\n",
    "1. Resize each image to 256×256 pixels, convert it to CIE-Lab and split it in blocks of 16×16 pixels (i.e., 256 blocks in total).\n",
    "\n",
    "2. For each block, find the most occurring color. Ties are randomly resolved. If this color corresponds to less than 5 occurrences (out of 256), select an arbitrary color from the block.\n",
    "\n",
    "3. At this point, we have extracted 256 Lab colors per image. The set of 256×$N$ colors from all images is clustered using a k-means algorithm, producing a $k_c$ Lab colors palette.\n",
    "\n",
    "My data set is already converted to a smaller dimension, so I'll be using blocks of 10x10 on 160x160 images instead (still 256 blocks in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create color profiles for RGB <-> LAB conversions\n",
    "srgb_profile = ImageCms.createProfile(\"sRGB\")\n",
    "lab_profile  = ImageCms.createProfile(\"LAB\")\n",
    "\n",
    "rgb2lab_transform = ImageCms.buildTransformFromOpenProfiles(srgb_profile, lab_profile, \"RGB\", \"LAB\")\n",
    "lab2rgb_transform = ImageCms.buildTransformFromOpenProfiles(lab_profile, srgb_profile, \"LAB\", \"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_cielab(img: Image) -> Image:\n",
    "    # first make sure it's RGB\n",
    "    if img.mode != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "\n",
    "    # then apply transformation\n",
    "    return ImageCms.applyTransform(img, rgb2lab_transform)\n",
    "\n",
    "def convert_to_rgb(img: Image) -> Image:\n",
    "    return ImageCms.applyTransform(img, lab2rgb_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_cie = convert_to_cielab(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn color block extraction into a function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dominant_colors(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args: \n",
    "      image: np.array [W, H, C = 3] dtype=uint8\n",
    "    Returns: np.array [256, 3] dtype=uint8\n",
    "    \"\"\"\n",
    "    assert len(image.shape) == 3\n",
    "    (w, h, c) = image.shape\n",
    "    assert c == 3\n",
    "    \n",
    "    def dominant_color(block, occurrence_threshold=4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        block: np.array [W, H, 3]\n",
    "        occurrence_threshold: int if most occurring color is less than this,\n",
    "        pick a random color from the block instead. Using 4 instead of 5\n",
    "        because the blocks are also a bit smaller\n",
    "        \"\"\"\n",
    "        block = np.reshape(block, [-1, 3])\n",
    "        hist = {}\n",
    "        \n",
    "        for color in block:\n",
    "            [c,i,e] = color\n",
    "            key = (c, i, e)\n",
    "            if key in hist:\n",
    "                hist[key] += 1\n",
    "            else:\n",
    "                hist[key] = 1\n",
    "        \n",
    "        (color, count) = max(hist.items(), key=lambda e:e[1])\n",
    "        if count < occurrence_threshold:\n",
    "            # not significant enough, choose a random color\n",
    "            return list(random.choice(block))\n",
    "        return list(color)\n",
    "    \n",
    "    colors = np.zeros([N_BLOCKS, 3], dtype=np.uint8)\n",
    "    k = 0\n",
    "    for i in range(0, w, BLOCK_SIZE):\n",
    "        for j in range(0, h, BLOCK_SIZE):\n",
    "            block = image[i: i + BLOCK_SIZE, j: j + BLOCK_SIZE]\n",
    "            dcolor = dominant_color(block)\n",
    "            colors[k] = dcolor\n",
    "            k += 1\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what colors we get with the sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_colors = extract_dominant_colors(np.array(sample_image_cie))\n",
    "s = sample_colors\n",
    "#s = np.sort(sample_colors, axis=0)\n",
    "#s = np.unique(sample_colors, axis=0)\n",
    "s = np.reshape(s, [16, 16, 3])\n",
    "sample_colors_img = Image.fromarray(s, 'LAB')\n",
    "sample_colors_img = convert_to_rgb(sample_colors_img)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(sample_image)\n",
    "plt.figure(figsize=(3, 3))\n",
    "_ = plt.imshow(sample_colors_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks ok on this end!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual color codebook generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can fetch the dominant colors of each image, let's produce a color vocabulary (codebook) with k-means clustering. I'll be using Faiss for this, by accumulating all colors into a 2-dimensional array. Let's experiment with multiple values of $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_dominant_colors(files: list) -> np.ndarray:\n",
    "    \"\"\"Collect the dominant colors of the set into a single ndarray.\n",
    "    Args:\n",
    "      files: list of image file names\n",
    "    Returns:\n",
    "      np.ndarray [N * 256, 3] dtype=f32\n",
    "    \"\"\"\n",
    "    all_colors = np.zeros([len(files) * 256, 3], dtype=np.float32)\n",
    "    for i, file in enumerate(files):\n",
    "        img = Image.open(file).resize([160, 160])\n",
    "        img = np.array(convert_to_cielab(img))\n",
    "        colors = extract_dominant_colors(img)\n",
    "        all_colors[i * 256: (i + 1) * 256] = colors.astype(np.float32)\n",
    "    return all_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_codebook(colors, k, niter=25, gpu_res=None, gpu_device=None) -> (np.ndarray, faiss.Index):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      colors : np.ndarray [N, 3] of colors\n",
    "      k : the size of the codebook\n",
    "      niter : number of k-means clustering iterations\n",
    "      gpu_res : faiss.GpuResources or None, required for a GPU backed index\n",
    "      gpu_device : int or None, whether to make a GPU backed index\n",
    "    Returns: tuple (centroids, index)\n",
    "      centroids : np.array [k, 3]\n",
    "      index : faiss.Index trained with the codebook (L2 metric)\n",
    "    \"\"\"\n",
    "    # we'll use the Clustering API so that we can choose\n",
    "    # the clustering index\n",
    "    cp = faiss.ClusteringParameters()\n",
    "    cp.niter = niter\n",
    "    cp.verbose = False\n",
    "    cp.spherical = False\n",
    "    clus = faiss.Clustering(3, k, cp)\n",
    "    index = faiss.IndexFlatL2(3)\n",
    "    if gpu_res is not None and gpu_device is not None:\n",
    "        index = faiss.index_cpu_to_gpu(gpu_res, gpu_device, index)\n",
    "\n",
    "    clus.train(colors, index)\n",
    "    obj = faiss.vector_float_to_array(clus.obj)\n",
    "    loss = obj[-1]\n",
    "    print(\"Finished training codebook of size {}. Loss: {}\".format(k, loss))\n",
    "    centroids = faiss.vector_float_to_array(clus.centroids).reshape([k, 3])\n",
    "    return centroids, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_colors = collect_dominant_colors(SAMPLE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_16 = generate_codebook(x_colors, 16, niter=50)\n",
    "kmeans_32 = generate_codebook(x_colors, 32, niter=50)\n",
    "kmeans_64 = generate_codebook(x_colors, 64, niter=50)\n",
    "kmeans_128 = generate_codebook(x_colors, 128, niter=50)\n",
    "kmeans_256 = generate_codebook(x_colors, 256, niter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the codebook in the index. We can use it directly to build our bags of colors. We can also see how the codebook looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_codebook(centroids, figsize=(6,2)):\n",
    "    # sort the colors, so that they look pretty\n",
    "    carr = centroids.tolist()\n",
    "    carr = sorted(carr, key=lambda v: v[2])\n",
    "    carr = np.reshape(np.array(carr, dtype=np.float32), [-1, 16, 3])\n",
    "    # convert to image\n",
    "    codebook_img = Image.fromarray(carr, 'LAB')\n",
    "    codebook_img = convert_to_rgb(codebook_img)\n",
    "    plt.figure(figsize=figsize)\n",
    "    _ = plt.imshow(codebook_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_codebook(kmeans_16[0])\n",
    "view_codebook(kmeans_32[0])\n",
    "view_codebook(kmeans_64[0])\n",
    "view_codebook(kmeans_128[0])\n",
    "view_codebook(kmeans_256[0], figsize=(12, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_16 = None\n",
    "kmean_32 = None\n",
    "kmeans_64 = None\n",
    "kmeans_128 = None\n",
    "kmeans_256 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, time to use more of the data set! Since our data set is too big for k-means clustering, we'll pick a random portion to serve as a template set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TEMPLATE = 25000 # twenty-five thousand\n",
    "RANDOM_SEED = 386104\n",
    "\n",
    "print(\"Using {} template samples\".format(N_TEMPLATE))\n",
    "random.seed(RANDOM_SEED)\n",
    "TEMPLATE_FILES = random.sample(ALL_FILES, k=N_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_colors = collect_dominant_colors(TEMPLATE_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power up! We'll use the GPU for building and retrieving from these codebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = faiss.StandardGpuResources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_64 = generate_codebook(template_colors, 64, niter=100, gpu_res=res, gpu_device=0)\n",
    "kmeans_128 = generate_codebook(template_colors, 128, niter=100, gpu_res=res, gpu_device=0)\n",
    "kmeans_256 = generate_codebook(template_colors, 256, niter=100, gpu_res=res, gpu_device=0)\n",
    "kmeans_512 = generate_codebook(template_colors, 512, niter=100, gpu_res=res, gpu_device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_codebook(kmeans_64[0])\n",
    "view_codebook(kmeans_128[0])\n",
    "view_codebook(kmeans_256[0])\n",
    "view_codebook(kmeans_512[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Color generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each color in an image, look for the nearest color in the codebook, and increment that position in the bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bags(codebook: faiss.Idex, files: iterable) -> np.ndarray:\n",
    "    \"\"\"Generate the bags of colors.\n",
    "    Args:\n",
    "      codebook: faiss.Index containing the codebook\n",
    "      files: list of file names (length N)\n",
    "    Returns:\n",
    "      np.array [N, k]\n",
    "    \"\"\"\n",
    "    assert codebook.ntotal > 0\n",
    "    all_bags = np.zeros([len(files), codebook.ntotal], dtype=np.float32)\n",
    "    for i, file in enumerate(files):\n",
    "        img = Image.open(file).resize([160, 160])\n",
    "        img = np.array(convert_to_cielab(img), dtype=np.float32).reshape([-1, 3])\n",
    "        # batch search for the code of pixels\n",
    "        codes = codebook.assign(img, 1)\n",
    "        for j in range(len(img)):\n",
    "            all_bags[i, codes[j]] += 1\n",
    "    return all_bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_bags = generate_bags(kmeans_256[1], SAMPLE_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how a bag looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_bag(x: np.ndarray):\n",
    "    # the histogram of the data\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    plt.bar(range(len(x)), x, facecolor='blue', alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_bag(sample_bags[0])\n",
    "view_bag(sample_bags[12])\n",
    "view_bag(sample_bags[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bags are often sparse, with some colors of high frequency. These bags can be normalized to attenuate this effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag normalization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_normalize(bocs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Linearly normalize the bags so that the maximum of each bag is 1.\"\"\"\n",
    "    return bocs / np.max(bocs, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_normalize(bocs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"tf-idf normalization.\"\"\"\n",
    "    tf = bocs / np.sum(1e-10 + bocs, axis=1, keepdims=True)\n",
    "    dcount = np.sum(bocs.astype(np.bool).astype(np.float), axis=0)\n",
    "    idf = np.log(len(bocs) / dcount)\n",
    "    return tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_normalize(bocs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Power-law and L1 vector normalization.\"\"\"\n",
    "    # element-wise square root, then L1 normalization\n",
    "    o = np.sqrt(bocs)\n",
    "    o /= np.sum(o, axis=1, keepdims=True)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max normalization\n",
    "nbags = max_normalize(sample_bags)\n",
    "view_bag(nbags[0])\n",
    "view_bag(nbags[1])\n",
    "view_bag(nbags[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td-idf normalization\n",
    "nbags = tf_idf_normalize(sample_bags)\n",
    "view_bag(nbags[0])\n",
    "view_bag(nbags[1])\n",
    "view_bag(nbags[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power-law + L1 normalization\n",
    "nbags = power_normalize(sample_bags)\n",
    "view_bag(nbags[0])\n",
    "view_bag(nbags[1])\n",
    "view_bag(nbags[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all bags in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will save the outcome in an hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = \"bocs-256-train.h5\"\n",
    "z = generate_bags(kmeans_256[1], ALL_FILES)\n",
    "# no normalization, this can be done later\n",
    "k = z.shape[1]\n",
    "n_samples = len(ALL_FILES)\n",
    "with h5.File(OUTPUT_FILE, mode='w') as f:\n",
    "    f.create_dataset('data', data=z, shape=[n_samples, k], dtype='float32')\n",
    "    h5ids = f.create_dataset('id', shape=[n_samples], dtype=h5.special_dtype(vlen=str))\n",
    "    for (i, bag) in enumerate(z):\n",
    "        h5set[i] = bag\n",
    "        h5ids[i] = path.basename(ALL_FILES[i])[:-4]\n",
    "print(\"Bags of colors (palette of size {}) was saved in {}\".format(k, OUTPUT_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all bags in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = \"bocs-256-test.h5\"\n",
    "z = generate_bags(kmeans_256[1], TEST_FILES)\n",
    "k = z.shape[1]\n",
    "n_samples = len(TEST_FILES)\n",
    "with h5.File(OUTPUT_FILE, mode='w') as f:\n",
    "    f.create_dataset('data', data=z, shape=[n_samples, k], dtype='float32')\n",
    "    h5ids = f.create_dataset('id', shape=[n_samples], dtype=h5.special_dtype(vlen=str))\n",
    "    for i, filename in enumerate(TEST_FILES):\n",
    "        h5ids[i] = path.basename(TEST_FILES[i])[:-4]\n",
    "print(\"Bags of colors (palette of size {}) was saved in {}\".format(k, OUTPUT_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all, folks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
